@book{Albert2009,
  address = {New York, NY},
  author = {Albert, Jim},
  doi = {10.1007/978-0-387-92298-0},
  isbn = {978-0-387-92297-3},
  mendeley-groups = {statistica},
  publisher = {Springer New York},
  title = {{Bayesian Computation with R}},
  url = {http://link.springer.com/10.1007/978-0-387-92298-0},
  year = {2009}
}
@article{Andrews2013,
  author = {Andrews, Mark and Baguley, Thom},
  doi = {10.1111/bmsp.12004},
  file = {:media/michele/DATA/Dropbox/SCNlab/LETTERATURA/statistics/bmsp.12004.pdf:pdf},
  issn = {00071102},
  journal = {British Journal of Mathematical and Statistical Psychology},
  mendeley-groups = {statistica},
  month = {feb},
  number = {1},
  pages = {1--7},
  pmid = {23330865},
  title = {{Prior approval: The growth of Bayesian methods in psychology}},
  url = {http://doi.wiley.com/10.1111/bmsp.12004},
  volume = {66},
  year = {2013}
}
@article{Kruschke2012,
  abstract = {The use of Bayesian methods for data analysis is creating a revolution in fields ranging from genetics to marketing. Yet, results of our literature review, including more than 10,000 articles published in 15 journals from January 2001 and December 2010, indicate that Bayesian approaches are essentially absent from the organizational sciences. Our article introduces organizational science researchers to Bayesian methods and describes why and how they should be used. We use multiple linear regression as the framework to offer a step-by-step demonstration, including the use of software, regarding how to implement Bayesian methods. We explain and illustrate how to determine the prior distribution, compute the posterior distribution, possibly accept the null value, and produce a write-up describing the entire Bayesian process, including graphs, results, and their interpretation. We also offer a summary of the advantages of using Bayesian analysis and examples of how specific published research based on frequentist analysis-based approaches failed to benefit from the advantages offered by a Bayesian approach and how using Bayesian analyses would have led to richer and, in some cases, different substantive conclusions. We hope that our article will serve as a catalyst for the adoption of Bayesian methods in organizational science research. {\textcopyright} The Author(s) 2012.},
  author = {Kruschke, John K. and Aguinis, Herman and Joo, Harry},
  doi = {10.1177/1094428112457829},
  file = {:media/michele/DATA/Dropbox/SCNlab/LETTERATURA/statistics/1094428112457829.pdf:pdf},
  issn = {1094-4281},
  journal = {Organizational Research Methods},
  keywords = {Monte Carlo,bootstrapping),computer simulation procedures (e.g.,multilevel research,quantitative research},
  mendeley-groups = {statistica},
  month = {oct},
  number = {4},
  pages = {722--752},
  title = {{The Time Has Come: Bayesian Methods for Data Analysis in the Organizational Sciences }},
  url = {http://journals.sagepub.com/doi/10.1177/1094428112457829},
  volume = {15},
  year = {2012}
}
@article{Stefan2019,
  abstract = {The possibility that certain microorganisms might be beneficial to human health is highlighted by the numerous consumer products containing probiotic bacteria. Probiotics are typically administered in food that, following entry into the gastrointestinal tract, results in measurable health-promoting effects. Although there is a growing list of health benefits provided by the consumption of probiotics, their precise mechanisms of action remain largely unknown. Recent molecular- and genomics-based studies are starting to provide insight into the ways probiotic bacteria sense and adapt to the gastrointestinal tract environment. Complementary approaches using host cell in vitro systems together with animal models and human volunteers are revealing specific intestinal cell responses to probiotics. These studies should ultimately disclose the molecular mechanisms and pinpoint the bacterial and host effector molecules and pathways by which probiotics are able to modulate human health.},
  author = {Stefan, Angelika M. and Gronau, Quentin Frederik and Sch{\"{o}}nbrodt, Felix D. and Wagenmakers, Eric-Jan},
  doi = {10.3758/s13428-018-01189-8},
  file = {:media/michele/DATA/Dropbox/SCNlab/LETTERATURA/statistics/Stefan2019_Article_ATutorialOnBayesFactorDesignAn.pdf:pdf},
  isbn = {1342801801189},
  issn = {1554-3528},
  journal = {Behavior Research Methods},
  keywords = {Bayes Factor,Design Analysis,Power Analysis,Sample Size,Statistical Evidence},
  mendeley-groups = {statistica},
  month = {jun},
  number = {3},
  pages = {1042--1058},
  title = {{A tutorial on Bayes Factor Design Analysis using an informed prior}},
  url = {http://link.springer.com/10.3758/s13428-018-01189-8},
  volume = {51},
  year = {2019}
}
@article{Etz2016,
  abstract = {We revisit the results of the recent Reproducibility Project: Psychology by the Open Science Collaboration. We compute Bayes factors - a quantity that can be used to express comparative evidence for an hypothesis but also for the null hypothesis - for a large subset (N = 72) of the original papers and their corresponding replication attempts. In our computation, we take into account the likely scenario that publication bias had distorted the originally published results. Overall, 75% of studies gave qualitatively similar results in terms of the amount of evidence provided. However, the evidence was often weak (i.e., Bayes factor < 10). The majority of the studies (64%) did not provide strong evidence for either the null or the alternative hypothesis in either the original or the replication, and no replication attempts provided strong evidence in favor of the null. In all cases where the original paper provided strong evidence but the replication did not (15%), the sample size in the replication was smaller than the original. Where the replication provided strong evidence but the original did not (10%), the replication sample size was larger. We conclude that the apparent failure of the Reproducibility Project to replicate many target effects can be adequately explained by overestimation of effect sizes (or overestimation of evidence against the null hypothesis) due to small sample sizes and publication bias in the psychological literature. We further conclude that traditional sample sizes are insufficient and that a more widespread adoption of Bayesian methods is desirable.},
  author = {Etz, Alexander and Vandekerckhove, Joachim},
  doi = {10.1371/journal.pone.0149794},
  editor = {Marinazzo, Daniele},
  file = {:media/michele/DATA/Dropbox/SCNlab/LETTERATURA/statistics/pone.0149794.pdf:pdf},
  issn = {1932-6203},
  journal = {PLOS ONE},
  mendeley-groups = {statistica},
  month = {feb},
  number = {2},
  pages = {e0149794},
  pmid = {26919473},
  title = {{A Bayesian Perspective on the Reproducibility Project: Psychology}},
  url = {https://dx.plos.org/10.1371/journal.pone.0149794},
  volume = {11},
  year = {2016}
}
@article{Kruschke2010,
  abstract = {Although Bayesian models of mind have attracted great interest from cognitive scientists, Bayesian methods for data analysis have not. This article reviews several advantages of Bayesian data analysis over traditional null-hypothesis significance testing. Bayesian methods provide tremendous flexibility for data analytic models and yield rich information about parameters that can be used cumulatively across progressive experiments. Because Bayesian statistical methods can be applied to any data, regardless of the type of cognitive model (Bayesian or otherwise) that motivated the data collection, Bayesian methods for data analysis will continue to be appropriate even if Bayesian models of mind lose their appeal.},
  author = {Kruschke, John K},
  doi = {10.1016/j.tics.2010.05.001},
  issn = {1879-307X},
  journal = {Trends in cognitive sciences},
  keywords = {Bayes Theorem,Humans,Reproducibility of Results,Research Design,Statistics as Topic},
  mendeley-groups = {Thesis,statistica},
  month = {jul},
  number = {7},
  pages = {293--300},
  pmid = {20542462},
  publisher = {Elsevier Ltd},
  title = {{What to believe: Bayesian methods for data analysis.}},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/20542462},
  volume = {14},
  year = {2010}
}
@article{Wagenmakers2018,
  abstract = {Bayesian parameter estimation and Bayesian hypothesis testing present attractive alternatives to classical inference using confidence intervals and p values. In part I of this series we outline ten prominent advantages of the Bayesian approach. Many of these advantages translate to concrete opportunities for pragmatic researchers. For instance, Bayesian hypothesis testing allows researchers to quantify evidence and monitor its progression as data come in, without needing to know the intention with which the data were collected. We end by countering several objections to Bayesian hypothesis testing. Part II of this series discusses JASP, a free and open source software program that makes it easy to conduct Bayesian estimation and testing for a range of popular statistical scenarios (Wagenmakers et al. this issue).},
  author = {Wagenmakers, Eric-Jan and Marsman, Maarten and Jamil, Tahira and Ly, Alexander and Verhagen, Josine and Love, Jonathon and Selker, Ravi and Gronau, Quentin F. and {\v{S}}m{\'{i}}ra, Martin and Epskamp, Sacha and Matzke, Dora and Rouder, Jeffrey N. and Morey, Richard D.},
  doi = {10.3758/s13423-017-1343-3},
  file = {:media/michele/DATA/Dropbox/SCNlab/LETTERATURA/statistics/Wagenmakers2018_Article_BayesianInferenceForPsychology.pdf:pdf},
  issn = {1069-9384},
  journal = {Psychonomic Bulletin & Review},
  keywords = {Bayes factor,Hypothesis test,Posterior distribution,Statistical evidence},
  mendeley-groups = {statistica},
  month = {feb},
  number = {1},
  pages = {35--57},
  pmid = {28779455},
  title = {{Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications}},
  url = {http://link.springer.com/10.3758/s13423-017-1343-3},
  volume = {25},
  year = {2018}
}
@book{Gelman2006,
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models, first published in 2007, is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.},
  address = {Cambridge},
  author = {Gelman, Andrew and Hill, Jennifer},
  doi = {10.1017/CBO9780511790942},
  isbn = {9780511790942},
  mendeley-groups = {Thesis},
  publisher = {Cambridge University Press},
  title = {{Data Analysis Using Regression and Multilevel/Hierarchical Models}},
  url = {http://books.google.it/books/about/Data_Analysis_Using_Regression_and_Multi.html?id=c9xLKzZWoZ4C&pgis=1 http://ebooks.cambridge.org/ref/id/CBO9780511790942},
  year = {2006}
}
@book{Kruschke2014,
  abstract = {There is an explosion of interest in Bayesian statistics, primarily because recently created computational methods have finally made Bayesian analysis obtainable to a wide audience. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan provides an accessible approach to Bayesian data analysis, as material is explained clearly with concrete examples. The book begins with the basics, including essential concepts of probability and random sampling, and gradually progresses to advanced hierarchical modeling methods for realistic data. Included are step-by-step instructions on how to conduct Bayesian data analyses in the popular and free software R and WinBugs. This book is intended for first-year graduate students or advanced undergraduates. It provides a bridge between undergraduate training and modern Bayesian methods for data analysis, which is becoming the accepted research standard. Knowledge of algebra and basic calculus is a prerequisite.},
  archivePrefix = {arXiv},
  arxivId = {arXiv:1011.1669v3},
  author = {Kruschke, John K.},
  booktitle = {Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan, Second Edition},
  doi = {10.1016/B978-0-12-405888-0.09999-2},
  edition = {2},
  eprint = {arXiv:1011.1669v3},
  file = {::},
  isbn = {9780124058880},
  issn = {1385-4046},
  mendeley-groups = {statistica},
  pages = {1--759},
  pmid = {15003161},
  publisher = {Elsevier Inc.},
  title = {{Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan, second edition}},
  url = {http://dx.doi.org/10.1016/B978-0-12-405888-0.09999-2},
  year = {2014}
}
@article{Cumming2014,
  abstract = {We need to make substantial changes to how we conduct research. First, in response to heightened concern that our published research literature is incomplete and untrustworthy, we need new requirements to ensure research integrity. These include prespecification of studies whenever possible, avoidance of selection and other inappropriate data-analytic practices, complete reporting, and encouragement of replication. Second, in response to renewed recognition of the severe flaws of null-hypothesis significance testing (NHST), we need to shift from reliance on NHST to estimation and other preferred techniques. The new statistics refers to recommended practices, including estimation based on effect sizes, confidence intervals, and meta-analysis. The techniques are not new, but adopting them widely would be new for many researchers, as well as highly beneficial. This article explains why the new statistics are important and offers guidance for their use. It describes an eight-step new-statistics strategy for research with integrity, which starts with formulation of research questions in estimation terms, has no place for NHST, and is aimed at building a cumulative quantitative discipline.},
  author = {Cumming, Geoff},
  doi = {10.1177/0956797613504966},
  issn = {1467-9280},
  journal = {Psychological science},
  mendeley-groups = {Thesis},
  month = {jan},
  number = {1},
  pages = {7--29},
  pmid = {24220629},
  title = {{The new statistics: why and how.}},
  url = {http://pss.sagepub.com/content/early/2013/11/07/0956797613504966},
  volume = {25},
  year = {2014}
}
@book{gelman2013bayesian,
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  mendeley-groups = {statistica},
  publisher = {CRC press},
  title = {{Bayesian data analysis}},
  year = {2013}
}
@article{Kruschke2018,
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed "the New Statistics" (Cumming, 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequen-tist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis. Keywords Null hypothesis significance testing {\textperiodcentered} Bayesian inference {\textperiodcentered} Bayes factor {\textperiodcentered} Confidence interval {\textperiodcentered} Credible interval {\textperiodcentered} Highest density interval {\textperiodcentered} Region of practical equivalence {\textperiodcentered} Meta-analysis {\textperiodcentered} Power analysis {\textperiodcentered} Effect size {\textperiodcentered} Randomized controlled trial {\textperiodcentered} Equivalence testing The New Statistics emphasizes a shift of emphasis away from null hypothesis significance testing (NHST) to "esti-mation based on effect sizes, confidence intervals, and meta-analysis" (Cumming, 2014, p. 7). There are many reasons to eschew NHST, with its seductive lapse to black-and-white thinking about the presence or absence of effects. There are also many reasons to promote instead a cumulative science that incrementally improves estimates of magnitudes and uncertainty. These reasons were recently highlighted in a prominent statement from the American Statistical Association (ASA; Wasserstein & Lazar, 2016) that will be summarized later in this article. Recent decades have also seen repeated calls to shift emphasis away from frequentist methods to Bayesian analysis (e.g., Lindley, 1975). In this article, we review both of these recommended shifts of emphasis in the practice of data analysis, and we promote their convergence in Bayesian methods for estimation. The goals of the New Statistics are better achieved by Bayesian methods than by frequentist methods. In that sense, we recommend a Bayesian New Statistics. Within the domain of Bayesian methods, we have a more nuanced emphasis. Bayesian methods provide a coherent framework for hypothesis testing, so when null hypothesis testing is the crux of the research then Bayesian null hypothesis testing should be carefully used. But we also believe that typical analyses should not routinely stop with hypothesis testing alone. In that sense, we recommend a New Bayesian Statistics , that is, Bayesian analyses that also consider estimates of magnitudes and uncertainty, along with meta-analyses. This article begins with an extensive description of fre-quentist and Bayesian approaches to null hypothesis testing and estimation with confidence or credible intervals. Subsequently , the article explains Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis. We hope to demonstrate that Bayesian approaches to all these analyses are more direct, more intuitive, and more informative than frequentist approaches.},
  author = {Kruschke, John K and Liddell, Torrin M},
  doi = {10.3758/s13423-016-1221-4},
  file = {::;::},
  journal = {Psychon Bull Rev},
  keywords = {Bayes factor,Bayesian inference,Confidence interval,Credible interval,Effect size,Equivalence testing,Highest density interval,Meta-analysis,Null hypothesis significance testing,Power analysis,Randomized controlled trial,Region of practical equivalence},
  mendeley-groups = {statistica},
  pages = {178--206},
  title = {{The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective}},
  volume = {25},
  year = {2018}
}
@article{Scandola2021,
  author = {Scandola, Michele and Romano, Daniele},
  doi = {10.1016/j.neuropsychologia.2021.107834},
  issn = {00283932},
  journal = {Neuropsychologia},
  month = {mar},
  pages = {107834},
  title = {{Bayesian Multilevel Single Case Models using 'Stan'. A new tool to study single cases in Neuropsychology}},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0028393221000853},
  year = {2021}
}
@incollection{Raftery1995,
  address = {Cambridge},
  author = {Raftery, Adrian E},
  booktitle = {Sociological Methodology},
  editor = {Marsden, P V},
  file = {:home/michele/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raftery - 1995 - Bayesian Model Selection in Social Research.pdf:pdf},
  number = {1995},
  pages = {111--163},
  publisher = {Blackwells},
  title = {{Bayesian Model Selection in Social Research}},
  volume = {25},
  year = {1995}
}
@article{Stefan,
  author = {Stefan, Angelika M and Katsimpokis, Dimitris and Gronau, Quentin F and Wagenmakers, Eric-Jan},
  doi = {10.31234/osf.io/8xkqd},
  file = {:media/michele/DATA/Dropbox/SCNlab/LETTERATURA/statistics/Expert_Agreement_in_Prior_Elicitation(1).pdf:pdf},
  journal = {PsyArXiv},
  mendeley-groups = {statistica},
  title = {{Expert Agreement in Prior Elicitation and its Effects on Bayesian Inference}},
  url = {https://osf.io/vqszj/.},
  year = {2021}
}
@article{Dickey1971,
  abstract = {A general weak convergence theory is developed for time-sequential censored rank statistics in the two-sample problem of comparing time to failure between two treatment groups, such as in the case of a clinical trial in which patients enter serially and, after being randomly allocated to one of two treatments, are followed until they fail or withdraw from the study or until the study is terminated. Applications of the theory to time-sequential tests based on these censored rank statistics are also discussed.},
  author = {Dickey, James M.},
  doi = {10.1214/aoms/1177693507},
  file = {:media/michele/DATA/Dropbox/SCNlab/LETTERATURA/statistics/Dickey 1971.pdf:pdf},
  issn = {0003-4851},
  journal = {The Annals of Mathematical Statistics},
  mendeley-groups = {statistica},
  month = {feb},
  number = {1},
  pages = {204--223},
  title = {{The Weighted Likelihood Ratio, Linear Hypotheses on Normal Location Parameters}},
  url = {http://projecteuclid.org/euclid.aoms/1177693507},
  volume = {42},
  year = {1971}
}
@article{Carlin1995,
  author = {Carlin, Bradley P. and Chib, Siddhartha},
  file = {::},
  journal = {Journal of the RoyalStatistical Society B},
  mendeley-groups = {statistica},
  number = {3},
  pages = {473--484},
  title = {{Bayesian model choice via Markov Chain Monte Carlo method}},
  volume = {57},
  year = {1995}
}
@article{OHara2009,
  abstract = {The selection of variables in regression problems has occupied the minds of many statisticians. Several Bayesian variable selection methods have been developed, and we concentrate on the following methods: Kuo & Mallick, Gibbs Variable Selection (GVS), Stochastic Search Variable Selection (SSVS), adaptive shrinkage with Je{\AE}reys' prior or a Laplacian prior, and reversible jump MCMC. We review these methods, in the context of their di{\AE}erent properties. We then implement the methods in BUGS, using both real and simulated data as examples, and investigate how the di{\AE}erent methods perform in practice. Our results suggest that SSVS, reversible jump MCMC and adaptive shrinkage methods can all work well, but the choice of which method is better will depend on the priors that are used, and also on how they are implemented.},
  author = {O'Hara, R. B. and Sillanp{\"{a}}{\"{a}}, M. J.},
  doi = {10.1214/09-BA403},
  isbn = {1936-0975},
  issn = {19360975},
  journal = {Bayesian Analysis},
  keywords = {BUGS,MCMC,Variable selection},
  mendeley-groups = {statistica},
  number = {1},
  pages = {85--118},
  pmid = {273483200007},
  title = {{A review of bayesian variable selection methods: What, how and which}},
  volume = {4},
  year = {2009}
}
@article{Kuo198,
  abstract = {simple method for subset selection of independent variables in regression models is proposed. We expand the usual regression equation to an equation that incorporates all possible subsets of predictors by adding indicator variables as parameters. The vector of indicator variables dictates which predictors to include. Several choices of priors can be employed for the unknown regression coefficients and the unknown indicator parameters. The posterior distribution of the indicator vector is approximated by means of the Markov Chain Monte Carlo algorithm. We select subsets with high posterior probabilities. In addition to linear models, we consider generalized linear models.},
  author = {Kuo, Lynn and Mallick, Bani},
  journal = {Sankhyā: The Indian Journal of Statistics, Series B},
  mendeley-groups = {statistica},
  number = {1},
  pages = {65--81},
  title = {{Variable Selection for Regression Models}},
  volume = {60},
  year = {1998}
}
@article{Vehtari2016,
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparing of predictive errors between two models. We implement the computations in an R package called 'loo' and demonstrate using models fit with the Bayesian inference package Stan.},
  archivePrefix = {arXiv},
  arxivId = {1507.04544},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  doi = {10.1007/s11222-016-9696-4},
  eprint = {1507.04544},
  isbn = {1507.04544},
  issn = {0960-3174},
  journal = {Statistics and Computing},
  keywords = {Bayesian computation,K-fold cross-validation,Leave-one-out cross-validation (LOO),Pareto smoothed importance sampling (PSIS),Stan,Widely applicable information criterion (WAIC)},
  mendeley-groups = {statistica},
  month = {sep},
  number = {5},
  pages = {1413--1432},
  publisher = {Springer US},
  title = {{Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC}},
  url = {http://link.springer.com/10.1007/s11222-016-9696-4},
  volume = {27},
  year = {2017}
}
@article{Gelman1992,
  abstract = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were contin- ued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normal- ity after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random- effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
  author = {Gelman, Andrew and Rubin, Donald B},
  file = {::},
  journal = {Statistical Science},
  keywords = {algorithm,and phrases,bayesian inference,convergence of stochastic,ecm,em,gibbs sampler,importance sampling,metropolis,multiple imputation,processes,random-effects model,sir},
  mendeley-groups = {statistica},
  number = {4},
  pages = {457--472},
  title = {{Inference from Iterative Simulation Using Multiple Sequences}},
  volume = {7},
  year = {1992}
}
@article{Gelman2013,
  abstract = {Abstract: Posterior predictive p-values do not in general have uniform distributions under the null hypothesis (except in the special case of ancillary test variables) but instead tend to have distributions more concentrated near 0.5. From different perspectives, such ...\n},
  archivePrefix = {arXiv},
  arxivId = {math.PR/0000000},
  author = {Gelman, Andrew},
  doi = {10.1214/13-EJS854},
  eprint = {0000000},
  issn = {1935-7524},
  journal = {Electronic Journal of Statistics},
  keywords = {and phrases,bayesian inference,model checking,p-value,posterior,predictive check,u-value},
  mendeley-groups = {statistica},
  pages = {1--8},
  primaryClass = {math.PR},
  title = {{Understanding posterior p-values}},
  year = {2013}
}



